{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c71ea46-14fd-4a69-baab-3b6389d06b7b",
   "metadata": {},
   "source": [
    "# SGLBO & SPSA Optimization on Iris Dataset\n",
    "\n",
    "*This notebook implements and compares SGLBO and SPSA optimizers on the Iris dataset using a Qiskit Quantum Neural Network (QNN).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3f0cd-b82f-4e6e-a128-1e06705c534b",
   "metadata": {},
   "source": [
    "##### Cell 1: Environment check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c52d8-e8ea-4394-9ad8-a8ed34d90af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version, PackageNotFoundError\n",
    "import numpy as np\n",
    "\n",
    "pkgs = [\n",
    "    \"qiskit\",\n",
    "    \"qiskit-aer\",\n",
    "    \"qiskit-ibm-runtime\",\n",
    "    \"qiskit-machine-learning\",\n",
    "    \"qiskit-algorithms\"\n",
    "]\n",
    "\n",
    "print(\"Installed Qiskit packages:\")\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        print(f\"{p:24s}\", version(p))\n",
    "    except PackageNotFoundError:\n",
    "        print(f\"{p:24s}  — not installed —\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df96ac-bd00-4619-b3af-c8e90864eb54",
   "metadata": {},
   "source": [
    "##### Cell 2: Constants and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671ecfd-61ac-40b5-b98e-bab18b240605",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 16\n",
    "plateau_eps = 1e-2\n",
    "plateau_window = 10\n",
    "budgets = [5_000,10_000] #[10_000, 50_000, 100_000]\n",
    "n_seeds = 2 #20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4137b9e-2545-4be5-ac51-09714bda20a6",
   "metadata": {},
   "source": [
    "##### Cell 3: Load/preprocess Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e508247-5312-42cf-8dc9-399c0efedb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing, model_selection\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "y = (y == 0).astype(int)\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d2f09-58a9-4c79-8fd2-ebb9ea030cb6",
   "metadata": {},
   "source": [
    "##### Cell 4: Circuit and QNN setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbda34-e280-4175-b33b-aed3a3ca70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "\n",
    "num_qubits = X_train.shape[1]\n",
    "feature_map = ZZFeatureMap(num_qubits, reps=2)\n",
    "ansatz = RealAmplitudes(num_qubits, reps=2, entanglement=\"full\")\n",
    "qc = feature_map.compose(ansatz)\n",
    "estimator = Estimator(options={\"shots\": 1024})\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=qc,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    estimator=estimator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59077ef2-818f-4115-b62e-5ebf5f81fc02",
   "metadata": {},
   "source": [
    "##### Cell 5: Cost function and batch iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e63277-f95d-4ed5-a258-c0429e790c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(X, y, size=batch_size):\n",
    "    n = len(X)\n",
    "    while True:\n",
    "        idx = np.random.choice(n, size, replace=False)\n",
    "        yield X[idx], y[idx]\n",
    "\n",
    "train_batches = batch_iter(X_train, y_train, size=batch_size)\n",
    "\n",
    "def cost_fn(theta, shots, return_var=False, eps=1e-9):\n",
    "    Xb, yb = next(train_batches)\n",
    "\n",
    "    # (Re)set shot count for this mini-batch\n",
    "    if hasattr(estimator, \"set_options\"):\n",
    "        estimator.set_options(shots=shots)\n",
    "\n",
    "    # QNN raw output in [-1, 1]\n",
    "    raw = qnn.forward(Xb, theta).flatten()\n",
    "\n",
    "    # --- map to probability ---  p ∈ (0, 1)\n",
    "    probs = np.clip((raw + 1.0) * 0.5, eps, 1 - eps)\n",
    "\n",
    "    # Binary-cross-entropy loss\n",
    "    loss = -np.mean(yb * np.log(probs) + (1 - yb) * np.log(1 - probs))\n",
    "\n",
    "    if return_var:\n",
    "        var = np.mean(probs * (1 - probs) / shots)\n",
    "        return loss, var\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f631879-5825-49d1-bb09-85516629e71a",
   "metadata": {},
   "source": [
    "##### Cell 6: SGLBO class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413a37d-41d9-4e6e-b183-f68d6d885505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement as ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "class SGLBO:\n",
    "    \"\"\"\n",
    "    Stochastic-Gradient-Line Bayesian Optimisation for variational quantum circuits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta0 : 1-D numpy array\n",
    "        Initial parameter vector.\n",
    "    cost_fn : callable\n",
    "        Signature ``loss, var = cost_fn(theta, shots, return_var=True)``.\n",
    "        Must return an unbiased loss estimate and (optionally) its shot-noise variance.\n",
    "    kappa : float, optional\n",
    "        Gradient-variance threshold (see Eq. 34 of the paper).  Smaller ⇒ more shots.\n",
    "    alpha : float, optional\n",
    "        Fraction of the last iterations to suffix-average (Polyak averaging).\n",
    "    shots_grad_min / max : int\n",
    "        Lower / upper bound for adaptive shots used in a single gradient component.\n",
    "    shots_line : int\n",
    "        Total shots budget for each 1-D BO line search.\n",
    "    eta_bound : float\n",
    "        Search window for the step size η ∈ [−eta_bound, +eta_bound].\n",
    "    max_shots : int\n",
    "        Stop automatically when the *cumulative* shots exceed this value.\n",
    "    max_iter : int\n",
    "        Hard ceiling on iterations (useful if `max_shots` is ∞).\n",
    "    dtype : torch dtype\n",
    "        Precision for the GP model (double by default).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, theta0, cost_fn,\n",
    "                 kappa=0.05, alpha=0.3,\n",
    "                 shots_grad_min=16, shots_grad_max=1024,\n",
    "                 shots_line=256,\n",
    "                 eta_bound=0.2,\n",
    "                 max_shots=np.inf,\n",
    "                 max_iter=10_000,\n",
    "                 dtype=torch.double):\n",
    "\n",
    "        self.theta = np.asarray(theta0, dtype=float)\n",
    "        self.cost_fn = cost_fn\n",
    "\n",
    "        # hyper-parameters\n",
    "        self.kappa = kappa\n",
    "        self.alpha = alpha\n",
    "        self.shots_grad_cur = shots_grad_min\n",
    "        self.shots_grad_min = shots_grad_min\n",
    "        self.shots_grad_max = shots_grad_max\n",
    "        self.shots_line = shots_line\n",
    "        self.eta_bound = eta_bound\n",
    "        self.max_shots = max_shots\n",
    "        self.max_iter = max_iter\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # bookkeeping\n",
    "        self.shots_used = 0\n",
    "        self.T = 0                         # iteration counter\n",
    "        self.history = []                  # theta, eta, shots_used, ...\n",
    "        self.avg_theta = np.zeros_like(self.theta)\n",
    "\n",
    "        # incremental GP data (1-D)\n",
    "        self.global_X = torch.empty(0, 1, dtype=dtype)\n",
    "        self.global_Y = torch.empty(0, 1, dtype=dtype)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. stochastic gradient with adaptive shots\n",
    "    # ------------------------------------------------------------------\n",
    "    def _gradient(self):\n",
    "        grad = np.zeros_like(self.theta)\n",
    "        for i in range(len(self.theta)):\n",
    "            shift = np.zeros_like(self.theta)\n",
    "            shift[i] = np.pi / 2           # parameter-shift rule\n",
    "\n",
    "            shots = self.shots_grad_cur\n",
    "            while True:\n",
    "                f_plus,  var_p = self.cost_fn(self.theta + shift,\n",
    "                                               shots, return_var=True)\n",
    "                f_minus, var_m = self.cost_fn(self.theta - shift,\n",
    "                                               shots, return_var=True)\n",
    "                var_grad = 0.25 * (var_p + var_m)\n",
    "                if var_grad <= self.kappa ** 2 or shots >= self.shots_grad_max:\n",
    "                     break\n",
    "                shots *= 2                   # double shots and retry\n",
    "\n",
    "            grad[i] = 0.5 * (f_plus - f_minus)\n",
    "            self.shots_used += 2 * shots\n",
    "            \n",
    "        self.shots_grad_cur = min(2 * self.shots_grad_cur, self.shots_grad_max)\n",
    "        return grad\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. 1-D Bayesian-optimisation line search (Expected Improvement)\n",
    "    # ------------------------------------------------------------------\n",
    "    def _line_bo(self, direction):\n",
    "        etas_raw = np.array([0.0, 0.1, -0.1]).reshape(-1, 1)\n",
    "        etas = etas_raw / (2 * self.eta_bound) + 0.5          # map to [0,1]\n",
    "\n",
    "        ys = np.array([self.cost_fn(self.theta + e_raw * direction,\n",
    "                            shots=self.shots_line // 3,\n",
    "                            return_var=False)\n",
    "               for e_raw in etas_raw])\n",
    "\n",
    "        X = torch.tensor(etas, dtype=self.dtype)\n",
    "        Y = torch.tensor(ys, dtype=self.dtype).unsqueeze(-1)\n",
    "\n",
    "        # append to global history and (re)fit 1-D GP\n",
    "        self.global_X = torch.cat([self.global_X, X])\n",
    "        self.global_Y = torch.cat([self.global_Y, Y])\n",
    "\n",
    "        gp = SingleTaskGP(self.global_X, self.global_Y)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        EI = ExpectedImprovement(gp, best_f=self.global_Y.min())\n",
    "        bounds = torch.tensor([[0.0], [1.0]], dtype=self.dtype)\n",
    "\n",
    "        eta_opt_unit, _ = optimize_acqf(EI, bounds=bounds, q=1,\n",
    "                                num_restarts=5, raw_samples=20)\n",
    "        eta_opt = (eta_opt_unit.item() - 0.5) * 2 * self.eta_bound\n",
    "        # spend the remaining shots_line shots on that candidate\n",
    "        self.shots_used += self.shots_line\n",
    "        return float(eta_opt)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. public API:  one optimisation step\n",
    "    # ------------------------------------------------------------------\n",
    "    def step(self):\n",
    "        if self.T >= self.max_iter or self.shots_used >= self.max_shots:\n",
    "            return False          # signal \"stop\"\n",
    "\n",
    "        g = self._gradient()\n",
    "        if self.shots_used >= self.max_shots:\n",
    "            return False\n",
    "        \n",
    "        d = g / np.linalg.norm(g)\n",
    "        eta = self._line_bo(d)\n",
    "        if self.shots_used >= self.max_shots:\n",
    "            return False\n",
    "\n",
    "        # parameter update\n",
    "        self.theta += eta * d\n",
    "\n",
    "        # suffix (Polyak) averaging\n",
    "        self.T += 1\n",
    "        self.history.append((self.theta.copy(), eta, self.shots_used))\n",
    "\n",
    "        # --- inside step(), suffix averaging ----------------------\n",
    "        if self.T > (1 - self.alpha) * max(1, self.T):\n",
    "           w = 1.0 / (self.alpha * self.T)\n",
    "           self.avg_theta = (1 - w) * self.avg_theta + w * self.theta\n",
    "        else:\n",
    "            self.avg_theta = self.theta.copy()   # not yet in suffix window\n",
    "\n",
    "        return True           # signal \"continue\"\n",
    "\n",
    "    # convenience helper ------------------------------------------------\n",
    "    def run(self):\n",
    "        \"\"\"Run until `max_shots` or `max_iter` is reached.\"\"\"\n",
    "        while self.step():\n",
    "            pass\n",
    "        return self.avg_theta   # best guess of optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416fb17-f934-44fa-a6d8-c48d5c00f064",
   "metadata": {},
   "source": [
    "##### Cell 7: Runner functions for SGLBO and SPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb7dc0-b5cf-4d2e-9872-38be9d9a3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sglbo(seed, budget_shots=50_000, verbose=False,cost_fn=None):\n",
    "    if cost_fn is None:                   # fall back to the global one\n",
    "        cost_fn = globals()[\"cost_fn\"]\n",
    "    rng = np.random.default_rng(seed)\n",
    "    theta0 = rng.standard_normal(ansatz.num_parameters)\n",
    "\n",
    "    opt = SGLBO(theta0, cost_fn,\n",
    "                max_shots=budget_shots, max_iter=300,\n",
    "                shots_line=128, shots_grad_min=32, shots_grad_max=256,\n",
    "                alpha=0.3, kappa=0.05)\n",
    "\n",
    "    shots_hist, loss_hist, acc_hist = [], [], []\n",
    "    stop_reason = \"unknown\"                       # initialise\n",
    "\n",
    "    while True:\n",
    "        cont = opt.step()                         # one optimiser step\n",
    "        if not cont:                              # budget or max-iter fuse\n",
    "            stop_reason = \"budget / max_iter\"\n",
    "            break\n",
    "\n",
    "        # ── diagnostics ──\n",
    "        shots_hist.append(opt.shots_used)\n",
    "\n",
    "        if hasattr(estimator, \"set_options\"):\n",
    "            estimator.set_options(shots=256)\n",
    "        loss_val = cost_fn(opt.theta, 256, False)\n",
    "        loss_hist.append(loss_val)\n",
    "\n",
    "        probs = (qnn.forward(X_test, opt.theta).flatten() + 1) * 0.5\n",
    "        acc_val = ((probs > 0.5).astype(int) == y_test).mean()\n",
    "        acc_hist.append(acc_val)\n",
    "        # ───────────────────────────────────────────────────────────────\n",
    "\n",
    "        if verbose and opt.T % 2 == 0:                        # console trace\n",
    "            print(f\"Iter {opt.T:2d} | shots {opt.shots_used:7d} \"\n",
    "                  f\"| grad_shots {opt.shots_grad_cur:4d} \"\n",
    "                  f\"| loss {loss_val:6.3f} | acc {acc_val:5.3f}\")\n",
    "\n",
    "        # plateau check (relative 1 % over last 10 logs)\n",
    "        flat = (len(loss_hist) > plateau_window and\n",
    "                abs(loss_hist[-1] - loss_hist[-1 - plateau_window]) <\n",
    "                plateau_eps * abs(loss_hist[-1 - plateau_window]))\n",
    "\n",
    "        if flat:\n",
    "            stop_reason = \"plateau\"\n",
    "            break                                  # early-stop fuse\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Run stopped due to:\", stop_reason,\n",
    "              \"| final shots:\", shots_hist[-1],\n",
    "              \"| best loss:\", np.min(loss_hist),\n",
    "              \"| best acc:\",  np.max(acc_hist))\n",
    "    \n",
    "    return (np.array(shots_hist),\n",
    "            np.array(loss_hist),\n",
    "            np.array(acc_hist),\n",
    "            opt.avg_theta)\n",
    "\n",
    "# SPSA\n",
    "from qiskit_algorithms.optimizers import SPSA\n",
    "def run_spsa(seed, budget_shots=50_000, *, verbose=False,cost_fn=None):\n",
    "    if cost_fn is None:                   # fall back to the global one\n",
    "        cost_fn = globals()[\"cost_fn\"]\n",
    "    rng         = np.random.default_rng(seed)\n",
    "    theta0      = rng.standard_normal(ansatz.num_parameters)\n",
    "\n",
    "    shots_per_eval  = 256\n",
    "    spsa_shots_used = 0\n",
    "    shots_hist, loss_hist, acc_hist = [], [], []\n",
    "    theta_last = theta0.copy()\n",
    "    stop_reason = \"unknown\"\n",
    "\n",
    "    # ───────── objective wrapper ─────────\n",
    "    def spsa_objective(theta):\n",
    "        nonlocal spsa_shots_used, theta_last, stop_reason\n",
    "        theta_last = theta\n",
    "\n",
    "        if hasattr(estimator, \"set_options\"):\n",
    "            estimator.set_options(shots=shots_per_eval)\n",
    "        loss = cost_fn(theta, shots_per_eval, False)\n",
    "\n",
    "\n",
    "        # ------- shot accounting --------\n",
    "        spsa_shots_used += shots_per_eval\n",
    "        if spsa_shots_used >= budget_shots:\n",
    "            stop_reason = \"budget\"\n",
    "            raise StopIteration\n",
    "        # ---------------------------------\n",
    "\n",
    "        # log once per optimiser iteration\n",
    "        if len(shots_hist) == 0 or spsa_shots_used > shots_hist[-1]:\n",
    "            shots_hist.append(spsa_shots_used)\n",
    "\n",
    "            if hasattr(estimator, \"set_options\"):\n",
    "                estimator.set_options(shots=256)\n",
    "            loss_val = cost_fn(theta, 256, False)\n",
    "            loss_hist.append(loss_val)\n",
    "\n",
    "            probs = (qnn.forward(X_test, theta).flatten() + 1) * 0.5\n",
    "            acc_val = ((probs > 0.5).astype(int) == y_test).mean()\n",
    "            acc_hist.append(acc_val)\n",
    "\n",
    "            # console trace\n",
    "            if verbose:\n",
    "                print(f\"SPSA iter {len(shots_hist):3d} | \"\n",
    "                      f\"shots {spsa_shots_used:7d} | \"\n",
    "                      f\"loss {loss_val:6.3f} | acc {acc_val:5.3f}\")\n",
    "\n",
    "            # plateau check (relative 1 %)\n",
    "            flat = (len(loss_hist) > plateau_window and\n",
    "                    abs(loss_hist[-1] - loss_hist[-1 - plateau_window]) <\n",
    "                    plateau_eps * abs(loss_hist[-1 - plateau_window]))\n",
    "            if flat:\n",
    "                stop_reason = \"plateau\"\n",
    "                raise StopIteration\n",
    "\n",
    "        return loss\n",
    "    # ────────────────────────────────────\n",
    "\n",
    "    spsa = SPSA(maxiter=300, learning_rate=0.05, perturbation=0.1)\n",
    "\n",
    "    try:\n",
    "        res = spsa.minimize(fun=spsa_objective, x0=theta0)\n",
    "        theta_final  = res.x\n",
    "        stop_reason  = \"maxiter\"\n",
    "    except StopIteration:\n",
    "        theta_final = theta_last\n",
    "\n",
    "    # one-line summary\n",
    "    if verbose:\n",
    "        print(f\"SPSA stopped due to: {stop_reason} | \"\n",
    "              f\"final shots: {shots_hist[-1]}\")\n",
    "\n",
    "    return (np.array(shots_hist),\n",
    "            np.array(loss_hist),\n",
    "            np.array(acc_hist),\n",
    "            theta_final,\n",
    "            stop_reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279acce5-e0b8-49cd-9832-bb8331249438",
   "metadata": {},
   "source": [
    "##### Cell 8: Run all experiments and collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11472b58-fc97-44a7-bd5e-1e7c284f9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {opt: {b: [] for b in budgets} for opt in [\"sglbo\", \"spsa\"]}\n",
    "\n",
    "for b in budgets:\n",
    "    for s in range(n_seeds):\n",
    "\n",
    "        # --- SGLBO ----------------------------------------------------\n",
    "        res_sglbo = run_sglbo(s, b)\n",
    "        if len(res_sglbo[0]) > 0:                \n",
    "            results[\"sglbo\"][b].append(res_sglbo)\n",
    "        else:\n",
    "            print(f\"[sglbo] seed {s} budget {b} produced no data – skipped\")\n",
    "\n",
    "        # --- SPSA -----------------------------------------------------\n",
    "        res_spsa = run_spsa(s, b)\n",
    "        if len(res_spsa[0]) > 0:\n",
    "            results[\"spsa\"][b].append(res_spsa)\n",
    "        else:\n",
    "            print(f\"[spsa] seed {s} budget {b} produced no data – skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f462df-5bfb-4377-acd6-c9b6ec1689f1",
   "metadata": {},
   "source": [
    "##### Cell 9: Plotting utilities and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a01b60-f463-43b0-90e0-1c1819315973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def best_so_far(arr):\n",
    "    return np.minimum.accumulate(arr)\n",
    "\n",
    "for b in budgets:\n",
    "    plt.figure()\n",
    "    grid = np.arange(8, b + 1, 8)  # <<<<<< match shot increments!\n",
    "    for name in [\"sglbo\", \"spsa\"]:\n",
    "        curves = []\n",
    "        for sh, lh, *_ in results[name][b]:\n",
    "            if len(sh) == 0 or len(lh) == 0:\n",
    "                continue\n",
    "            running_best = best_so_far(lh)\n",
    "            curves.append(\n",
    "                np.interp(\n",
    "                    grid,\n",
    "                    sh,\n",
    "                    running_best,\n",
    "                    left=running_best[0],\n",
    "                    right=running_best[-1]\n",
    "                )\n",
    "            )\n",
    "        if len(curves) == 0:\n",
    "            print(f\"[{name}] No data for budget {b}\")\n",
    "            continue\n",
    "        curves = np.vstack(curves)\n",
    "        median = np.nanmedian(curves, axis=0)\n",
    "        q1, q3 = np.nanpercentile(curves, [25, 75], axis=0)\n",
    "        plt.plot(grid, median, label=name.upper())\n",
    "        plt.fill_between(grid, q1, q3, alpha=0.25)\n",
    "    plt.title(f\"Budget {b:,} shots – {n_seeds} seeds\")\n",
    "    plt.xlabel(\"cumulative shots\")\n",
    "    plt.ylabel(\"best MSE so far\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a1cd6-700c-431f-bfda-1856b13c265b",
   "metadata": {},
   "source": [
    "##### Cell 10: Build noise models and create Aer/Backend estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eadb87-c8a7-49b6-b11d-7e8a88dc8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error, ReadoutError\n",
    "from qiskit.primitives import BackendEstimator, StatevectorEstimator\n",
    "\n",
    "def make_noise_model(p_1q=0.001, p_2q=0.01, p_ro=0.02):\n",
    "    noise = NoiseModel()\n",
    "    noise.add_all_qubit_quantum_error(depolarizing_error(p_1q, 1), ['u3'])\n",
    "    noise.add_all_qubit_quantum_error(depolarizing_error(p_2q, 2), ['cx'])\n",
    "    ro = ReadoutError([[1-p_ro, p_ro], [p_ro, 1-p_ro]])\n",
    "    for q in range(num_qubits):\n",
    "        noise.add_readout_error(ro, [q])\n",
    "    return noise\n",
    "\n",
    "levels = {\n",
    "    \"noiseless\": None,\n",
    "    \"low\":    make_noise_model(0.0005, 0.005, 0.01),\n",
    "    \"medium\": make_noise_model(0.001,  0.01,  0.02),\n",
    "    \"high\":   make_noise_model(0.003,  0.03,  0.05)\n",
    "}\n",
    "\n",
    "estimators = {}\n",
    "for tag, nm in levels.items():\n",
    "    if nm is None:\n",
    "        estimators[tag] = StatevectorEstimator()\n",
    "    else:\n",
    "        simul = AerSimulator(noise_model=nm)\n",
    "        simul.set_options(shots=1024)\n",
    "        estimators[tag] = BackendEstimator(backend=simul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b010bb-c43e-4f96-8f44-3213969609a5",
   "metadata": {},
   "source": [
    "##### Cell 11: Run SGLBO & SPSA across noise levels and log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b7b2-adb5-4301-884b-a0c0d0ed532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_results = {tag: {opt: {b: [] for b in budgets}\n",
    "                       for opt in [\"sglbo\", \"spsa\"]}\n",
    "                 for tag in estimators}\n",
    "\n",
    "for tag, est in estimators.items():\n",
    "    print(f\"\\n=== Running {tag} noise ===\")\n",
    "    estimator = est  # update global variable, so cost_fn uses the right one\n",
    "\n",
    "    for seed in range(n_seeds):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        theta0 = rng.standard_normal(ansatz.num_parameters)\n",
    "\n",
    "        # new QNN, new batch generator for *this* seed\n",
    "        qnn = EstimatorQNN(\n",
    "            circuit=qc,\n",
    "            input_params=feature_map.parameters,\n",
    "            weight_params=ansatz.parameters,\n",
    "            estimator=estimator\n",
    "        )\n",
    "        train_batches = batch_iter(X_train, y_train, size=batch_size)\n",
    "\n",
    "        # use global cost_fn, no need to redefine\n",
    "        for b in budgets:\n",
    "            noise_results[tag][\"sglbo\"][b].append(\n",
    "                run_sglbo(seed, b, cost_fn=cost_fn)\n",
    "            )\n",
    "            noise_results[tag][\"spsa\"][b].append(\n",
    "                run_spsa(seed, b, cost_fn=cost_fn)\n",
    "            )\n",
    "    print(f\"{tag} noise: all seeds done ✔︎\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39147757-ce1b-4cbc-8fb5-bac920fc98de",
   "metadata": {},
   "source": [
    "##### Cell 12: Plot best-so-far loss vs. shots for each noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be005b3b-aeef-4cb0-bd2e-f0368663ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = {\"sglbo\": \"tab:blue\", \"spsa\": \"tab:orange\"}\n",
    "linestyles = {\"noiseless\":\"-\", \"low\":\"--\", \"medium\":\"-.\", \"high\":\":\"}\n",
    "\n",
    "for tag in levels:\n",
    "    plt.figure()\n",
    "    for name in [\"sglbo\", \"spsa\"]:\n",
    "        grid = np.arange(8, budgets[-1]+1, 8)\n",
    "        curves = []\n",
    "        for sh, lh, *_ in noise_results[tag][name][budgets[-1]]:\n",
    "            # Only add if sh and lh are both non-empty\n",
    "            if len(sh) == 0 or len(lh) == 0:\n",
    "                continue\n",
    "            running_best = np.minimum.accumulate(lh)\n",
    "            curves.append(\n",
    "                np.interp(grid, sh, running_best, left=running_best[0], right=running_best[-1])\n",
    "            )\n",
    "        if len(curves) == 0:\n",
    "            print(f\"[{tag} {name}] No data for budget {budgets[-1]}\")  # <— for debug\n",
    "            continue\n",
    "        curves = np.vstack(curves)\n",
    "        median = np.nanmedian(curves, axis=0)\n",
    "        q1, q3 = np.nanpercentile(curves, [25, 75], axis=0)\n",
    "        plt.plot(grid, median, label=f\"{name.upper()} – {tag}\",\n",
    "                 color=colors[name], linestyle=linestyles[tag])\n",
    "        plt.fill_between(grid, q1, q3, alpha=0.18, color=colors[name])\n",
    "    plt.title(f\"Iris – best loss vs shots ({tag} noise)\")\n",
    "    plt.xlabel(\"cumulative shots\")\n",
    "    plt.ylabel(\"best MSE so far\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5b907-d9d9-41c4-8143-68b177e88468",
   "metadata": {},
   "source": [
    "##### Cell 13: Connect to IBM Quantum and do a 10 k-shot smoke-test on hardware (or fallback simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abd3ab-757b-4795-a421-a958e0203be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to IBM Quantum and run a quick 10 k-shot smoke-test\n",
    "# for both optimisers on the least-busy real backend (or a\n",
    "# simulator fallback if all real devices are unavailable).\n",
    "#\n",
    "# Prereqs:\n",
    "#   • Stored an IBM Quantum API token \n",
    "#   • `num_qubits` is already defined (4 for Iris)\n",
    "#   • run_sglbo / run_spsa are in scope from earlier cells\n",
    "#   • cost_fn/qnn refer to the *global* `estimator` object\n",
    "\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Estimator as RtEstimator\n",
    "from qiskit_ibm_runtime import Session\n",
    "\n",
    "# 1️⃣  Authenticate and choose a backend\n",
    "svc = QiskitRuntimeService(channel=\"ibm_quantum\")\n",
    "try:\n",
    "    backend = svc.least_busy(simulator=False, min_num_qubits=num_qubits)\n",
    "except Exception as exc:\n",
    "    print(\"No real backends available → falling back to a simulator.\")\n",
    "    backend = svc.least_busy(simulator=True, min_num_qubits=num_qubits)\n",
    "\n",
    "print(\"Running on backend:\", backend.name)\n",
    "\n",
    "# 2️⃣  Open a persistent runtime session so multiple jobs share the queue slot\n",
    "session = Session(service=svc, backend=backend)\n",
    "\n",
    "# 3️⃣  Create a Runtime Estimator and expose it globally\n",
    "estimator = RtEstimator(session=session, options={\"shots\": 1024})\n",
    "globals()[\"estimator\"] = estimator      # make cost_fn/qnn see this one\n",
    "\n",
    "# 4️⃣  Smoke-test each optimiser with a 10 k-shot budget\n",
    "for helper in [run_sglbo, run_spsa]:\n",
    "    result = helper(seed=0, budget_shots=10_000)\n",
    "    shots_hist = result[0]\n",
    "    stop_reason = result[4] if len(result) == 5 else \"finished\"\n",
    "    print(f\"{helper.__name__} stopped due to {stop_reason} – \"\n",
    "          f\"shots used: {shots_hist[-1]}\")\n",
    "\n",
    "# 5️⃣  Clean up\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sglbo-env)",
   "language": "python",
   "name": "sglbo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
